12/06/25, 19:15:10 : Using device: cuda 
12/06/25, 19:15:10 : Starting training process...
n_epoch : 10, batch size : 32, learning rate : 0.001 
12/06/25, 19:15:10 : Dataset loaded. Training samples: 6112, Validation samples: 764 
12/06/25, 19:15:13 : Freezing convolutional layers for feature extraction (N 32 and beyond) 
12/06/25, 19:15:15 : Model Summary:
===================================================================================================================
Layer (type:depth-idx)                   Input Shape               Output Shape              Param #
===================================================================================================================
VGG                                      [32, 3, 224, 224]         [32, 2]                   --
├─Sequential: 1-1                        [32, 3, 224, 224]         [32, 512, 7, 7]           --
│    └─Conv2d: 2-1                       [32, 3, 224, 224]         [32, 64, 224, 224]        (1,792)
│    └─ReLU: 2-2                         [32, 64, 224, 224]        [32, 64, 224, 224]        --
│    └─Conv2d: 2-3                       [32, 64, 224, 224]        [32, 64, 224, 224]        (36,928)
│    └─ReLU: 2-4                         [32, 64, 224, 224]        [32, 64, 224, 224]        --
│    └─MaxPool2d: 2-5                    [32, 64, 224, 224]        [32, 64, 112, 112]        --
│    └─Conv2d: 2-6                       [32, 64, 112, 112]        [32, 128, 112, 112]       (73,856)
│    └─ReLU: 2-7                         [32, 128, 112, 112]       [32, 128, 112, 112]       --
│    └─Conv2d: 2-8                       [32, 128, 112, 112]       [32, 128, 112, 112]       (147,584)
│    └─ReLU: 2-9                         [32, 128, 112, 112]       [32, 128, 112, 112]       --
│    └─MaxPool2d: 2-10                   [32, 128, 112, 112]       [32, 128, 56, 56]         --
│    └─Conv2d: 2-11                      [32, 128, 56, 56]         [32, 256, 56, 56]         (295,168)
│    └─ReLU: 2-12                        [32, 256, 56, 56]         [32, 256, 56, 56]         --
│    └─Conv2d: 2-13                      [32, 256, 56, 56]         [32, 256, 56, 56]         (590,080)
│    └─ReLU: 2-14                        [32, 256, 56, 56]         [32, 256, 56, 56]         --
│    └─Conv2d: 2-15                      [32, 256, 56, 56]         [32, 256, 56, 56]         (590,080)
│    └─ReLU: 2-16                        [32, 256, 56, 56]         [32, 256, 56, 56]         --
│    └─MaxPool2d: 2-17                   [32, 256, 56, 56]         [32, 256, 28, 28]         --
│    └─Conv2d: 2-18                      [32, 256, 28, 28]         [32, 512, 28, 28]         (1,180,160)
│    └─ReLU: 2-19                        [32, 512, 28, 28]         [32, 512, 28, 28]         --
│    └─Conv2d: 2-20                      [32, 512, 28, 28]         [32, 512, 28, 28]         (2,359,808)
│    └─ReLU: 2-21                        [32, 512, 28, 28]         [32, 512, 28, 28]         --
│    └─Conv2d: 2-22                      [32, 512, 28, 28]         [32, 512, 28, 28]         (2,359,808)
│    └─ReLU: 2-23                        [32, 512, 28, 28]         [32, 512, 28, 28]         --
│    └─MaxPool2d: 2-24                   [32, 512, 28, 28]         [32, 512, 14, 14]         --
│    └─Conv2d: 2-25                      [32, 512, 14, 14]         [32, 512, 14, 14]         (2,359,808)
│    └─ReLU: 2-26                        [32, 512, 14, 14]         [32, 512, 14, 14]         --
│    └─Conv2d: 2-27                      [32, 512, 14, 14]         [32, 512, 14, 14]         (2,359,808)
│    └─ReLU: 2-28                        [32, 512, 14, 14]         [32, 512, 14, 14]         --
│    └─Conv2d: 2-29                      [32, 512, 14, 14]         [32, 512, 14, 14]         (2,359,808)
│    └─ReLU: 2-30                        [32, 512, 14, 14]         [32, 512, 14, 14]         --
│    └─MaxPool2d: 2-31                   [32, 512, 14, 14]         [32, 512, 7, 7]           --
├─AdaptiveAvgPool2d: 1-2                 [32, 512, 7, 7]           [32, 512, 7, 7]           --
├─Sequential: 1-3                        [32, 25088]               [32, 2]                   --
│    └─Linear: 2-32                      [32, 25088]               [32, 4096]                102,764,544
│    └─ReLU: 2-33                        [32, 4096]                [32, 4096]                --
│    └─Dropout: 2-34                     [32, 4096]                [32, 4096]                --
│    └─Linear: 2-35                      [32, 4096]                [32, 4096]                16,781,312
│    └─ReLU: 2-36                        [32, 4096]                [32, 4096]                --
│    └─Dropout: 2-37                     [32, 4096]                [32, 4096]                --
│    └─Sequential: 2-38                  [32, 4096]                [32, 2]                   --
│    │    └─Linear: 3-1                  [32, 4096]                [32, 512]                 2,097,664
│    │    └─ReLU: 3-2                    [32, 512]                 [32, 512]                 --
│    │    └─Dropout: 3-3                 [32, 512]                 [32, 512]                 --
│    │    └─Linear: 3-4                  [32, 512]                 [32, 2]                   1,026
===================================================================================================================
Total params: 136,359,234
Trainable params: 121,644,546
Non-trainable params: 14,714,688
Total mult-adds (G): 495.42
===================================================================================================================
Input size (MB): 19.27
Forward/backward pass size (MB): 3470.39
Params size (MB): 545.44
Estimated Total Size (MB): 4035.10
=================================================================================================================== 
12/06/25, 19:15:15 : Optimizer: Adam 
12/06/25, 19:32:38 : Epoch 1/10 - Train Loss: 0.32 - Train accuracy: 87.60% - Val loss: 0.26 - Val Accuracy: 89.01% 
12/06/25, 19:32:40 : New best model saved at /home/ids/tmahandry-23/projet/art_classification/output/train_logs/20250612-191456/best_vgg16.pth 
12/06/25, 19:47:34 : Epoch 2/10 - Train Loss: 0.27 - Train accuracy: 88.27% - Val loss: 0.25 - Val Accuracy: 89.27% 
12/06/25, 19:47:36 : New best model saved at /home/ids/tmahandry-23/projet/art_classification/output/train_logs/20250612-191456/best_vgg16.pth 
12/06/25, 20:07:41 : Epoch 3/10 - Train Loss: 0.27 - Train accuracy: 88.69% - Val loss: 0.22 - Val Accuracy: 90.05% 
12/06/25, 20:07:43 : New best model saved at /home/ids/tmahandry-23/projet/art_classification/output/train_logs/20250612-191456/best_vgg16.pth 
12/06/25, 20:28:41 : Epoch 4/10 - Train Loss: 0.25 - Train accuracy: 89.43% - Val loss: 0.22 - Val Accuracy: 91.75% 
12/06/25, 20:28:43 : New best model saved at /home/ids/tmahandry-23/projet/art_classification/output/train_logs/20250612-191456/best_vgg16.pth 
12/06/25, 20:47:03 : Epoch 5/10 - Train Loss: 0.26 - Train accuracy: 89.09% - Val loss: 0.21 - Val Accuracy: 90.18% 
12/06/25, 21:07:29 : Epoch 6/10 - Train Loss: 0.24 - Train accuracy: 89.76% - Val loss: 0.21 - Val Accuracy: 90.58% 
12/06/25, 21:28:40 : Epoch 7/10 - Train Loss: 0.24 - Train accuracy: 89.50% - Val loss: 0.21 - Val Accuracy: 90.84% 
12/06/25, 21:55:10 : Epoch 8/10 - Train Loss: 0.24 - Train accuracy: 90.17% - Val loss: 0.20 - Val Accuracy: 91.36% 
12/06/25, 22:09:12 : Epoch 9/10 - Train Loss: 0.24 - Train accuracy: 89.35% - Val loss: 0.21 - Val Accuracy: 91.62% 
12/06/25, 22:29:20 : Epoch 10/10 - Train Loss: 0.24 - Train accuracy: 89.84% - Val loss: 0.21 - Val Accuracy: 91.62% 
12/06/25, 22:29:20 : Training complete. Best validation accuracy: 91.75% 
